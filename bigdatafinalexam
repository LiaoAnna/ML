# -*- coding: utf-8 -*-
"""bigdatafe.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ExIOlab6-NDJRqyCuFc-6keg5xa4X9NP
"""

from google.colab import drive
drive.mount('/content/drive')

from sklearn import preprocessing as pp
from sklearn.svm import SVC
from sklearn import preprocessing as pp
from sklearn import feature_selection as fs
from sklearn import decomposition as dc
from sklearn.preprocessing import StandardScaler
from sklearn import model_selection as ms
import pandas as pd
from sklearn.feature_selection import chi2
import numpy as np
from sklearn import datasets, preprocessing, decomposition, model_selection
from sklearn import ensemble, naive_bayes, metrics
from matplotlib import pyplot as plt
from mlxtend import plotting
from sklearn.metrics import accuracy_score
from sklearn import datasets, model_selection, tree, metrics
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn import impute as ip
import numpy as np
from sklearn import cluster
from sklearn.preprocessing import LabelEncoder
from sklearn import metrics
from scipy.cluster.hierarchy import dendrogram,linkage 
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN
from sklearn.decomposition import PCA
import pandas as pd
from sklearn import datasets as ds
from sklearn import preprocessing as pp
from scipy import stats 
import numpy as np
plt.rcParams["font.sans-serif"]="Microsoft JhengHei"
plt.rcParams["axes.unicode_minus"]=False
import seaborn as sns
from sklearn import feature_selection as fs
from sklearn import decomposition as dc
from sklearn.preprocessing import StandardScaler
from sklearn import ensemble as es
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from mlxtend.plotting import plot_decision_regions

import pandas as pd
from sklearn import datasets as ds
train=pd.read_csv("/content/drive/MyDrive/code/cancerpatient.csv")
train.info()
train

train.columns[[2,7,10,16,17,19]]

from sklearn import cluster
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
train['Level']=train['Level'].apply(lambda ss:2 if ss=='High' else 1 if ss=='Medium' else 0 )
train=train.drop('Patient Id',axis=1)
train.info()
train[:5]

train['Level'].value_counts().plot(kind='bar')

train['Air Pollution'].value_counts().plot(kind='bar',title="Air Pollution",xlabel='serious level',ylabel='number of patients')

train['Obesity'].value_counts().plot(kind='bar',title="Obesity",xlabel='serious level',ylabel='number of patients')

train['Passive Smoker'].value_counts().plot(kind='bar',title="Passive Smoker",xlabel='serious level',ylabel='number of patients')

train['Alcohol use'].value_counts().plot(kind='bar',title="Alcohol use",xlabel='serious level',ylabel='number of patients')

"""相關係數(heatmap)"""

cor=train.corr()
print(cor)
sns.heatmap(cor)

main1=train.drop(['Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring'],axis=1)
main2=train.drop(['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker'],axis=1)
main3=train.drop(['Chest Pain','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring'],axis=1)
main4=train.drop(['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Smoking','Passive Smoker'],axis=1)

main1cor=main1.corr()

print(sns.heatmap(main1cor,annot=True, fmt=".1f"))

main2cor=main2.corr()
print(sns.heatmap(main2cor,annot=True, fmt=".1f"))

main3cor=main3.corr()
print(sns.heatmap(main3cor,annot=True, fmt=".1f"))

main4cor=main4.corr()
print(sns.heatmap(main4cor,annot=True, fmt=".1f"))

#切割年齡
max_age=max(train['Age'])
min_age=min(train['Age'])
print('最小年紀',min_age,'最大年紀',max_age)
k=6
age_cut=pd.cut(train['Age'],k,labels=range(k))
print(age_cut)
# age_cut.hist()
age_f=['14~23','24~33','34~43','44~53','54~63','64~73']
age_train=train
age_train['Age_category']=age_cut
age_cut.value_counts().plot(kind='bar')

age_train[:20]

train['Age_category'][:20]

"""PCA"""

features=['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker','Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring']
x=train.loc[:,features].values
print(x[:5])
y=train.loc[:,['Level']].values
x=StandardScaler().fit_transform(x)
pca=dc.PCA(n_components=4)
model=pca.fit_transform(x)
df=pd.DataFrame(data=model,columns=['pc1','pc2','pc3','pc4'])
ptrain=pd.concat([df,train[['Level']]],axis=1)
ptrain

fig=plt.figure(figsize=(8,8))
ax=fig.add_subplot(1,1,1)
ax.set_xlabel('pc1',fontsize=15)
ax.set_ylabel('pc2',fontsize=15)
ax.set_title('PCA',fontsize=20)
targets=[0,1,2]
colors=['r','g','b']
for target, color in zip(targets,colors):
  indicesToKeep=ptrain['Level']==target
  ax.scatter(ptrain.loc[indicesToKeep,'pc1'],ptrain.loc[indicesToKeep,'pc2'],c=color,s=50)
ax.legend(targets)
ax.grid()

"""特徵選取"""

skbk=3
skb=fs.SelectKBest(fs.f_classif,k=skbk)
pskb=skb.fit_transform(x,y)
print(x[:3])

print(pskb[:3])
pskb_features=[]
features=['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker','Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring']
# for row in range(0,1000):
#   for col2 in range(0,skbk):
#     for col in range(0,23):
#       if pskb[row][col2]==x[row][col]:
#         pskb_features[row][col2]=features[col]
#         # print(features[col])
for col2 in range(0,skbk):
    for col in range(0,23):
      if pskb[0][col2]==x[0][col]:
        pskb_features.append(features[col])

print(pskb_features)

features=['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker','Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring']
pskb_features=[]
x=train.loc[:,features].values
y=train.loc[:,['Level']].values
x=StandardScaler().fit_transform(x)
for skbk in range(0,10):
  skb=fs.SelectKBest(fs.f_classif,k=skbk)
  pskb=skb.fit_transform(x,y)
  for col2 in range(0,skbk):
    for col in range(0,23):
      if pskb[0][col2]==x[0][col]:
        pskb_features.append(features[col])
  # pskb_features.append(skbk)

print(pskb_features)
list_p=[]
for pskbk in pskb_features:
  if pskbk not in list_p:
    list_p.append(pskbk)
print(list_p)

age1=age_train[age_train['Age_category']==0]
age1[:]
max(age1['Age'])

features=['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker','Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring']
pskb_features=[]
x=age1.loc[:,features].values
y=age1.loc[:,['Level']].values
x=StandardScaler().fit_transform(x)
for skbk in range(0,10):
  skb=fs.SelectKBest(fs.f_classif,k=skbk)
  pskb=skb.fit_transform(x,y)
  for col2 in range(0,skbk):
    for col in range(0,23):
      if pskb[0][col2]==x[0][col]:
        pskb_features.append(features[col])
  # pskb_features.append(skbk)

print(pskb_features)
list_p=[]
for pskbk in pskb_features:
  if pskbk not in list_p:
    list_p.append(pskbk)
print(list_p)

age2=age_train[age_train['Age_category']==1]
features=['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker','Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring']
pskb_features=[]
x=age2.loc[:,features].values
y=age2.loc[:,['Level']].values
x=StandardScaler().fit_transform(x)
for skbk in range(0,10):
  skb=fs.SelectKBest(fs.f_classif,k=skbk)
  pskb=skb.fit_transform(x,y)
  for col2 in range(0,skbk):
    for col in range(0,23):
      if pskb[0][col2]==x[0][col]:
        pskb_features.append(features[col])
  # pskb_features.append(skbk)

print(pskb_features)
list_p=[]
for pskbk in pskb_features:
  if pskbk not in list_p:
    list_p.append(pskbk)
print(list_p)

age3=age_train[age_train['Age_category']==2]
features=['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker','Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring']
pskb_features=[]
x=age3.loc[:,features].values
y=age3.loc[:,['Level']].values
x=StandardScaler().fit_transform(x)
for skbk in range(0,10):
  skb=fs.SelectKBest(fs.f_classif,k=skbk)
  pskb=skb.fit_transform(x,y)
  for col2 in range(0,skbk):
    for col in range(0,23):
      if pskb[0][col2]==x[0][col]:
        pskb_features.append(features[col])
  # pskb_features.append(skbk)

print(pskb_features)
list_p=[]
for pskbk in pskb_features:
  if pskbk not in list_p:
    list_p.append(pskbk)
print(list_p)

age4=age_train[age_train['Age_category']==3]
features=['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker','Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring']
pskb_features=[]
x=age4.loc[:,features].values
y=age4.loc[:,['Level']].values
x=StandardScaler().fit_transform(x)
for skbk in range(0,10):
  skb=fs.SelectKBest(fs.f_classif,k=skbk)
  pskb=skb.fit_transform(x,y)
  for col2 in range(0,skbk):
    for col in range(0,23):
      if pskb[0][col2]==x[0][col]:
        pskb_features.append(features[col])
  # pskb_features.append(skbk)

print(pskb_features)
list_p=[]
for pskbk in pskb_features:
  if pskbk not in list_p:
    list_p.append(pskbk)
print(list_p)

age5=age_train[age_train['Age_category']==4]
features=['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker','Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring']
pskb_features=[]
x=age5.loc[:,features].values
y=age5.loc[:,['Level']].values
x=StandardScaler().fit_transform(x)
for skbk in range(0,10):
  skb=fs.SelectKBest(fs.f_classif,k=skbk)
  pskb=skb.fit_transform(x,y)
  for col2 in range(0,skbk):
    for col in range(0,23):
      if pskb[0][col2]==x[0][col]:
        pskb_features.append(features[col])
  # pskb_features.append(skbk)

print(pskb_features)
list_p=[]
for pskbk in pskb_features:
  if pskbk not in list_p:
    list_p.append(pskbk)
print(list_p)

age6=age_train[age_train['Age_category']==5]
features=['Age','Gender','Air Pollution','Alcohol use','Dust Allergy','OccuPational Hazards','Genetic Risk','chronic Lung Disease','Balanced Diet','Obesity','Smoking','Passive Smoker','Chest Pain','Coughing of Blood','Fatigue','Weight Loss','Shortness of Breath','Wheezing','Swallowing Difficulty','Clubbing of Finger Nails','Frequent Cold','Dry Cough','Snoring']
pskb_features=[]
x=age6.loc[:,features].values
y=age6.loc[:,['Level']].values
x=StandardScaler().fit_transform(x)
for skbk in range(0,10):
  skb=fs.SelectKBest(fs.f_classif,k=skbk)
  pskb=skb.fit_transform(x,y)
  for col2 in range(0,skbk):
    for col in range(0,23):
      if pskb[0][col2]==x[0][col]:
        pskb_features.append(features[col])
  # pskb_features.append(skbk)

print(pskb_features)
list_p=[]
for pskbk in pskb_features:
  if pskbk not in list_p:
    list_p.append(pskbk)
print(list_p)

age6['Level'].value_counts().plot(kind='bar')

age5['Level'].value_counts().plot(kind='bar')

print(age4['Level'].value_counts())
age4['Level'].value_counts().plot(kind='bar')

print(age6['Level'].value_counts())

"""關聯分析"""

associ_rule_data=[['Obesity', 'Coughing of Blood', 'Passive Smoker', 'Balanced Diet', 'Dust Allergy', 'Alcohol use', 'Genetic Risk', 'Air Pollution', 'OccuPational Hazards'],
      ['Balanced Diet', 'Coughing of Blood', 'Passive Smoker', 'Chest Pain', 'Gender', 'Dust Allergy', 'Obesity', 'Genetic Risk', 'Alcohol use'],
      ['Air Pollution', 'Passive Smoker', 'Obesity', 'Alcohol use', 'Smoking', 'Coughing of Blood', 'Genetic Risk', 'Shortness of Breath', 'Balanced Diet'],
      ['Obesity', 'Coughing of Blood', 'Balanced Diet', 'OccuPational Hazards', 'Genetic Risk', 'Smoking', 'Passive Smoker', 'chronic Lung Disease', 'Dust Allergy'],
      ['Passive Smoker', 'Genetic Risk', 'Clubbing of Finger Nails', 'Alcohol use', 'Air Pollution', 'OccuPational Hazards', 'Shortness of Breath', 'Dust Allergy', 'Coughing of Blood'],
      ['Shortness of Breath', 'Fatigue', 'Obesity', 'Chest Pain', 'Dry Cough', 'Coughing of Blood', 'Passive Smoker', 'Wheezing', 'Balanced Diet']
      ]

te=TransactionEncoder()
te_ary=te.fit(associ_rule_data).transform(associ_rule_data)
te_ary
te.columns_

associ_rule_df=pd.DataFrame(te_ary,columns=te.columns_)
associ_rule_df

apriori(associ_rule_df,min_support=0.7)
apriori(associ_rule_df,min_support=0.7,use_colnames=True)

frequent_items=apriori(associ_rule_df,min_support=0.7,use_colnames=True)
frequent_items['length']=frequent_items['itemsets'].apply(lambda x:len(x))
frequent_items

frequent_items[(frequent_items['length']==3)&(frequent_items['support']>=0.6)]



rules=association_rules(frequent_items,metric='confidence',min_threshold=0.6)

rules["antencedent_len"]=rules["antecedents"].apply(lambda x:len(x))
rules

"""models

"""

list_m=[age1,age2,age3,age4,age5,age6]

target_col = "Level"
X = train.loc[:,train.columns!=target_col]
X1 = np.array(X)
y = train.loc[:,target_col].astype(np.integer)
y1 = np.array(y)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X1)
Xpca_train, Xpca_test, ypca_train, ypca_test = train_test_split(X_pca, y1, test_size=0.25, random_state=40)

target_col = "Level"
X = train.loc[:,train.columns[[9,11,13]]]
X1 = np.array(X)
y = train.loc[:,target_col].astype(np.integer)
y1 = np.array(y)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X1)
Xpca_train, Xpca_test, ypca_train, ypca_test = train_test_split(X_pca, y1, test_size=0.25, random_state=40)

# for m in list_m:
lr_model = LogisticRegression()
lr_model.fit(Xpca_train, ypca_train)

train_pred = lr_model.predict(Xpca_train)
test_pred = lr_model.predict(Xpca_test)

train_accuracy = accuracy_score(ypca_train, train_pred)
test_accuracy = accuracy_score(ypca_test, test_pred)
print("Accuracy of train set ：{:.4f}".format(train_accuracy))
print("Accuracy of test set：{:.4f}".format(test_accuracy))
plot_decision_regions(Xpca_test, ypca_test, clf=lr_model)

train.columns[[9,11,13]]

rf_20 = ensemble.RandomForestClassifier()
rf_20.fit(X_train,y_train)
train_pred = rf_20.predict(X_train)
test_pred = rf_20.predict(X_test)
train_accuracy = accuracy_score(y_train, train_pred)
test_accuracy = accuracy_score(y_test, test_pred)
print("Accuracy of train set ：{:.4f}".format(train_accuracy))
print("Accuracy of test set：{:.4f}".format(test_accuracy))
plotting.plot_decision_regions(X_test, y_test, clf=rf_20)

m=age2
mx = m.loc[:,m.columns[train.columns!=target_col]]
M = np.array(mx)
M_p = pca.fit_transform(M)
my = m.loc[:,target_col].astype(np.integer)
my1 = np.array(my)

rfcpa = ensemble.RandomForestClassifier()
rfcpa.fit(Xpca_train,ypca_train)
train_pred = rfcpa.predict(Xpca_train)
test_pred = rfcpa.predict(M_p)
train_accuracy = accuracy_score(ypca_train, train_pred)
test_accuracy = accuracy_score(my1, test_pred)
print("Accuracy of train set ：{:.4f}".format(train_accuracy))
print("Accuracy of test set：{:.4f}".format(test_accuracy))
plotting.plot_decision_regions(Xpca_test, ypca_test, clf=rfcpa)

for m in list_m:
  z=None
  
  mx = m.loc[:,m.columns[train.columns!=target_col]]
  M = np.array(mx)
  M_p = pca.fit_transform(M)
  my = m.loc[:,target_col].astype(np.integer)
  my1 = np.array(my)
  rfcpa = ensemble.RandomForestClassifier()
  rfcpa.fit(Xpca_train,ypca_train)
  train_pred = rfcpa.predict(Xpca_train)
  test_pred = rfcpa.predict(M_p)
  train_accuracy = accuracy_score(ypca_train, train_pred)
  test_accuracy = accuracy_score(my1, test_pred)

  print("Accuracy of train set ：{:.4f}".format(train_accuracy))
  print("Accuracy of test set：{:.4f}".format(test_accuracy))
  # z=plotting.plot_decision_regions(Xpca_test, ypca_test, clf=rfcpa)
  # z

for features1 in range(0,22):
  for features2 in range(0,22):
    X = train.loc[:,train.columns[[features1,features2]]]
    X1 = np.array(X)
    y = train.loc[:,target_col].astype(np.integer)
    y1 = np.array(y)
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X1)
    Xpca_train, Xpca_test, ypca_train, ypca_test = train_test_split(X_pca, y1, test_size=0.25, random_state=40)
    rfcpa = ensemble.RandomForestClassifier()
    rfcpa.fit(Xpca_train,ypca_train)
    train_pred = rfcpa.predict(Xpca_train)
    test_pred = rfcpa.predict(Xpca_test)
    train_accuracy = accuracy_score(ypca_train, train_pred)
    test_accuracy = accuracy_score(ypca_test, test_pred)
    
    if train_accuracy>=0.98 or test_accuracy>=0.98:
      print('yesss',train.columns[[features1,features2]])
      print("Accuracy of train set ：{:.4f}".format(train_accuracy))
      print("Accuracy of test set：{:.4f}".format(test_accuracy))

for features1 in range(0,22):
  for features2 in range(0,22):
    X = train.loc[:,train.columns[[features1,features2]]]
    X1 = np.array(X)
    y = train.loc[:,target_col].astype(np.integer)
    y1 = np.array(y)
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X1)
    Xpca_train, Xpca_test, ypca_train, ypca_test = train_test_split(X_pca, y1, test_size=0.25, random_state=40)

    gnbpca = naive_bayes.GaussianNB()
    gnbpca.fit(Xpca_train,ypca_train)
    train_pred = gnbpca.predict(Xpca_train)
    test_pred = gnbpca.predict(Xpca_test)


    train_accuracy = accuracy_score(ypca_train, train_pred)
    test_accuracy = accuracy_score(ypca_test, test_pred)
   
    if train_accuracy>=0.98 or test_accuracy>=0.98:
      print('yesss',train.columns[[features1,features2]])
      print("Accuracy of train set ：{:.4f}".format(train_accuracy))
      print("Accuracy of test set：{:.4f}".format(test_accuracy))



NB_F=[]
for features1 in range(0,22):
  for features2 in range(0,22):
    X = train.loc[:,train.columns[[features1,features2]]]
    X1 = np.array(X)
    y = train.loc[:,target_col].astype(np.integer)
    y1 = np.array(y)
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X1)
    Xpca_train, Xpca_test, ypca_train, ypca_test = train_test_split(X_pca, y1, test_size=0.25, random_state=40)

    gnbpca = naive_bayes.GaussianNB()
    gnbpca.fit(Xpca_train,ypca_train)
    train_pred = gnbpca.predict(Xpca_train)
    test_pred = gnbpca.predict(Xpca_test)


    train_accuracy = accuracy_score(ypca_train, train_pred)
    test_accuracy = accuracy_score(ypca_test, test_pred)
   
    if train_accuracy>=0.88 or test_accuracy>=0.88:
      if train.columns[features1] not in NB_F:
        NB_F.append(train.columns[features1])
      if train.columns[features2] not in NB_F:
        NB_F.append(train.columns[features2])
      print('yesss',train.columns[[features1,features2]])
      print("Accuracy of train set ：{:.4f}".format(train_accuracy))
      print("Accuracy of test set：{:.4f}".format(test_accuracy))
print('NB_F',NB_F)

SVM_F=[]
for features1 in range(0,22):
  for features2 in range(0,22):
    X = train.loc[:,train.columns[[features1,features2]]]
    X1 = np.array(X)
    y = train.loc[:,target_col].astype(np.integer)
    y1 = np.array(y)
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X1)
    Xpca_train, Xpca_test, ypca_train, ypca_test = train_test_split(X_pca, y1, test_size=0.25, random_state=40)

    sv = SVC(kernel='rbf',gamma='auto',probability=True)
    sv.fit(Xpca_train, ypca_train)

    train_pred = sv.predict(Xpca_train)
    test_pred = sv.predict(Xpca_test)


    train_accuracy = accuracy_score(ypca_train, train_pred)
    test_accuracy = accuracy_score(ypca_test, test_pred)
   
    if train_accuracy>=0.98 or test_accuracy>=0.98:
      print('yesss',train.columns[[features1,features2]])
      if train.columns[features1] not in SVM_F:
        SVM_F.append(train.columns[features1])
      if train.columns[features2] not in SVM_F:
      SVM_F.append(train.columns[features2])
      print("Accuracy of train set ：{:.4f}".format(train_accuracy))
      print("Accuracy of test set：{:.4f}".format(test_accuracy))
print(SVM_F)

print('SVM_F',SVM_F)

IR_F=[]
for features1 in range(0,22):
  for features2 in range(0,22):
    X = train.loc[:,train.columns[[features1,features2]]]
    X1 = np.array(X)
    y = train.loc[:,target_col].astype(np.integer)
    y1 = np.array(y)
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X1)
    Xpca_train, Xpca_test, ypca_train, ypca_test = train_test_split(X_pca, y1, test_size=0.25, random_state=40)

    lr_model = LogisticRegression()
    lr_model.fit(Xpca_train, ypca_train)

    train_pred = lr_model.predict(Xpca_train)
    test_pred = lr_model.predict(Xpca_test)


    train_accuracy = accuracy_score(ypca_train, train_pred)
    test_accuracy = accuracy_score(ypca_test, test_pred)
   
    if train_accuracy>=0.85 or test_accuracy>=0.85:
      if train.columns[features1] not in IR_F:
        IR_F.append(train.columns[features1])
      if train.columns[features2] not in IR_F:
        IR_F.append(train.columns[features2])
      print('yesss',train.columns[[features1,features2]])
      print("Accuracy of train set ：{:.4f}".format(train_accuracy))
      print("Accuracy of test set：{:.4f}".format(test_accuracy))
print('IR_F',IR_F)

for features1 in range(0,22):
  for features2 in range(0,22):
    X = train.loc[:,train.columns[[features1,features2]]]
    X1 = np.array(X)
    y = train.loc[:,target_col].astype(np.integer)
    y1 = np.array(y)
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X1)
    Xpca_train, Xpca_test, ypca_train, ypca_test = train_test_split(X_pca, y1, test_size=0.25, random_state=40)

    knn = KNeighborsClassifier()
    knn.fit(Xpca_train, ypca_train)

    train_pred = knn.predict(Xpca_train)
    test_pred = knn.predict(Xpca_test)


    train_accuracy = accuracy_score(ypca_train, train_pred)
    test_accuracy = accuracy_score(ypca_test, test_pred)
   
    if train_accuracy>=0.98 or test_accuracy>=0.98:
      print('yesss',train.columns[[features1,features2]])
      print("Accuracy of train set ：{:.4f}".format(train_accuracy))
      print("Accuracy of test set：{:.4f}".format(test_accuracy))



